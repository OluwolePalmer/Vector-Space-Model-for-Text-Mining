{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b9d68e-e46b-4af8-a2ff-19c82becc8e1",
   "metadata": {},
   "source": [
    "This document covers how to use the VECTOR SPACE MODEL in text data mining to determine the similarity between a given document and other documents in a corpus.\n",
    "I introduced two aproaches:\n",
    "\n",
    "    Approach 1 - Using Counter module in Collections library in Python\n",
    "\n",
    "    Approach 2 - Using Scikit-Learn library\n",
    "    \n",
    "At the end, you would also learn how to adjust for common words using the inverse document frequency idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c876ff-5dfa-4af8-b4f0-278f0177ed7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35fd903-e1fc-482d-8ad4-428d3d20e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this study, we would use a corpus which contains three documents\n",
    "\n",
    "corpus = [\"a rose is still a rose\", \"there is no there there\", \"rose is a rose is a rose is a rose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c534ff1-9255-4d27-aeab-2cf89d0f9f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3a9aa-f846-400b-aca1-92494a596918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d738c2e0-4888-4c83-bf0f-8c8ad36869d7",
   "metadata": {},
   "source": [
    "Approach 1 >>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1916d01b-42d5-49ff-9e20-20b7c5a62a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>rose</th>\n",
       "      <th>is</th>\n",
       "      <th>still</th>\n",
       "      <th>there</th>\n",
       "      <th>no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  rose   is  still  there   no\n",
       "0  2.0   2.0  1.0    1.0    0.0  0.0\n",
       "1  0.0   0.0  1.0    0.0    3.0  1.0\n",
       "2  3.0   4.0  3.0    0.0    0.0  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# determine the term frequency tf for each word in the corpus\n",
    "tf_df = pd.DataFrame([pd.Series(Counter(doc.split())) for doc in corpus]).fillna(0)\n",
    "tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168dac01-3a85-4039-8c2e-f50f40a38278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that calculates the cosine distance between two vectors\n",
    "import numpy as np\n",
    "\n",
    "# function to calculate the length of a vector v\n",
    "def length(v):\n",
    "    return np.sqrt((v**2).sum())\n",
    "\n",
    "# function to calculate the cosine distance\n",
    "def cos_dist(v, w):\n",
    "    return 1 - (v*w).sum()/(length(v)*length(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c75f08-8b2a-4dc4-acd6-1689adeef57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9046537410754407, 0.07804555427071147)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the cos_dist function\n",
    "cos_dist(tf_df.loc[0], tf_df.loc[1]), cos_dist(tf_df.loc[0], tf_df.loc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f97391-1bd2-4e22-a905-a0c5fed63e47",
   "metadata": {},
   "source": [
    "Interpretation: \n",
    "\n",
    "The angle between document 0 and document 2 is smaller, therefore, they have higher similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce14f5b-e655-4d5d-b134-5dd941a93c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555bbef-f67e-45bf-9e5b-6acbfff918e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "061c8efa-7c90-4ead-8716-f13b273a5e02",
   "metadata": {},
   "source": [
    "Approach 2 >>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d639580-e7b7-473e-9c14-c7238d96e0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2, 1, 0, 2, 1, 0],\n",
       "        [0, 1, 1, 0, 0, 3],\n",
       "        [3, 3, 0, 4, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "vec = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\") # creates a countvectorizer object\n",
    "tf_mat = vec.fit_transform(corpus) # to create a term frequency matrix\n",
    "tf_mat.todense() # to view the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98ca1b4-d549-4191-9f98-cb0a9c2f7afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90465374, 0.07804555]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pairwise_distances module to calculate the cosine distance\n",
    "pairwise_distances(tf_mat[0], tf_mat[1:], metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8d1dc-c6c5-4a04-ae30-d27b9ccf6077",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "The angle between document 0 and document 2 is smaller, therefore, they have higher similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed30592-e57f-4da0-9789-869e21cd9dab",
   "metadata": {},
   "source": [
    "You can also view the term frequency matrix in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5c9c4b-d57c-4f5d-95f4-b017bd8fa50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "      <th>no</th>\n",
       "      <th>rose</th>\n",
       "      <th>still</th>\n",
       "      <th>there</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  is  no  rose  still  there\n",
       "0  2   1   0     2      1      0\n",
       "1  0   1   1     0      0      3\n",
       "2  3   3   0     4      0      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = vec.get_feature_names_out()\n",
    "tf_mat_df = pd.DataFrame(tf_mat.todense(), columns=terms)\n",
    "tf_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9a1c7-24ac-4526-acb6-ba13f69e8698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc3053-537c-49cb-ad7c-51ebd2f845f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1759815d-cb96-42e5-9d9e-6b9c31db643e",
   "metadata": {},
   "source": [
    "Using Inverse Document Frequency IDF to adjust Term Frequency TF >>> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4046d-bbb7-4f7f-8270-e37fa699f2f6",
   "metadata": {},
   "source": [
    "There is a problem with using the term frequency tf as inputs in our calculation of the cosine distances without adjusting for common words. \n",
    "Therefore we should adjust for this using inverse document frequency idf.\n",
    "                          \n",
    "                        Ajusted term frequency (tf_idf) = tf*idf\n",
    "                          \n",
    "                        where:\n",
    "                            idf (t, D) = 1 + log(1/df)\n",
    "                          \n",
    "                            df = number of documents containing term t / total number of documents in the corpus\n",
    "\n",
    "We can use the calculated tf_idf to recalculate the cosine distances between two vectors (you can try it on your own)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe50283-d0b9-4d8e-be20-5ea40524a061",
   "metadata": {},
   "source": [
    "Scikit-Learn has a module which allows us to determine the tf_idf easily, see codes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718607c9-6e81-436a-a783-2e28bb0e51b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.        , 0.        , 2.81093022, 2.09861229, 0.        ],\n",
       "        [1.        , 2.09861229, 0.        , 0.        , 6.29583687],\n",
       "        [3.        , 0.        , 5.62186043, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer(smooth_idf=False, norm=None)\n",
    "tfidf_mat = vec.fit_transform(corpus)\n",
    "tfidf_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ca9ef9-a372-4aed-9f5c-809ab6d3644b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95915143, 0.19106774]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pairwise_distances module to calculate the cosine distance\n",
    "pairwise_distances(tfidf_mat[0], tfidf_mat[1:], metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b92c3-5941-4406-81a9-7888569b97a3",
   "metadata": {},
   "source": [
    "Let's see the adjusted tf-idf in a dataframe below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1210edc-13f1-49f1-b0b0-5d5e5d9a18a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>no</th>\n",
       "      <th>rose</th>\n",
       "      <th>still</th>\n",
       "      <th>there</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.81093</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.295837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.62186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is        no     rose     still     there\n",
       "0  1.0  0.000000  2.81093  2.098612  0.000000\n",
       "1  1.0  2.098612  0.00000  0.000000  6.295837\n",
       "2  3.0  0.000000  5.62186  0.000000  0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = vec.get_feature_names_out()\n",
    "tfidf_mat_df = pd.DataFrame(tfidf_mat.todense(), columns=terms)\n",
    "tfidf_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfeaa6f-c2ab-4a91-af43-dff7e500784c",
   "metadata": {},
   "source": [
    "Final Notes:\n",
    "\n",
    "The TfidfVectorizer removed the term 'a' from the tf_idf matrix because of either of the following reasons:\n",
    "\n",
    "- It is considered a stop word by the vectorizer.\n",
    "- It is considered a very short word and because short words don't carry much semantic meaning.\n",
    "- It is considered one of the very common words which can be removed by the TfidfVectorizer if they appear in too many documents.\n",
    "  By default, if a term appears in all documents, its inverse document frequency (IDF) becomes very low, and its impact on the overall TF-IDF score will be minimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
